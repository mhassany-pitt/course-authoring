{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "catalog = json.loads(open(\"./catalog.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"mysql.ini\")\n",
    "\n",
    "agg_db = mysql.connector.connect(\n",
    "    host=config[\"mysql\"][\"host\"],\n",
    "    user=config[\"mysql\"][\"username\"],\n",
    "    password=config[\"mysql\"][\"password\"],\n",
    "    ssl_disabled=True,  # Disable SSL\n",
    ")\n",
    "agg_cursor = agg_db.cursor()\n",
    "\n",
    "\n",
    "def insert_content_attrs(id, description, code, url, metadata):\n",
    "    print(\n",
    "        id, description, code, url, metadata\n",
    "    )\n",
    "    # agg_cursor.execute(\n",
    "    #     \"\"\"INSERT INTO aggregate.ent_content_attrs (content_id, description, code, preview_url, metadata) VALUES (%s, %s, %s, %s, %s)\"\"\",\n",
    "    #     (\n",
    "    #         id,\n",
    "    #         description,\n",
    "    #         code,\n",
    "    #         url,\n",
    "    #         json.dumps(metadata) if len(metadata.keys()) > 0 else \"\",\n",
    "    #     ),\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- PROCESS WEAT CONTENT -------------\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n",
    "def process_weat_pcex_items():\n",
    "    print(\"connection to aggregate database established\")\n",
    "    \n",
    "    prefixes = [\n",
    "        \"http://pawscomp2.sis.pitt.edu/pcex-authoring/assets/preview/index.html?load=\",\n",
    "        \"http://pawscomp2.sis.pitt.edu/pcex-authoring/preview/index.html?load=\"\n",
    "    ]\n",
    "\n",
    "    for _, item in enumerate(catalog):\n",
    "        matched_prefixes = [p for p in prefixes if item[\"url\"].startswith(p)]\n",
    "        if len(matched_prefixes) == 0:\n",
    "            continue\n",
    "        iframe_url = item[\"url\"][len(matched_prefixes[0]):].split(\"?\")\n",
    "        index = int(\n",
    "            [p for p in iframe_url[1].split(\"&\") if p.startswith(\"index=\")][0].split(\"=\")[1]\n",
    "        )\n",
    "        content = requests.get(iframe_url[0]).json()[0]\n",
    "        content = content[\"activityGoals\"][index]\n",
    "\n",
    "        metadata = dict()\n",
    "\n",
    "        if content[\"fullyWorkedOut\"] == False:\n",
    "            metadata[\"distractors\"] = []\n",
    "            for line in content[\"distractorList\"]:\n",
    "                line = line[\"line\"]\n",
    "                del line[\"id\"]\n",
    "                del line[\"indentLevel\"]\n",
    "                if \"number\" in line and line[\"number\"] > 0:\n",
    "                    line[\"line_number\"] = int(line[\"number\"])\n",
    "                del line[\"number\"]\n",
    "                metadata[\"distractors\"].append(line)\n",
    "\n",
    "        insert_content_attrs(\n",
    "            item[\"id\"],\n",
    "            content[\"goalDescription\"],\n",
    "            \"\\n\".join(\n",
    "                [\n",
    "                    l[\"content\"]\n",
    "                    for l in sorted(\n",
    "                        content[\"lineList\"],\n",
    "                        key=lambda l: int(l[\"number\"]),\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            item[\"url\"],\n",
    "            json.dumps(metadata) if len(metadata.keys()) > 0 else \"\",\n",
    "        )\n",
    "\n",
    "        print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "    agg_db.commit()\n",
    "\n",
    "\n",
    "\n",
    "process_weat_pcex_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- PROCESS PCEX-v1n2 CONTENT -------------\n",
    "\n",
    "import re\n",
    "import requests\n",
    "\n",
    "\n",
    "def process_pcex_v12_items():\n",
    "    print(\"connection to aggregate database established\")\n",
    "\n",
    "    prefixes = [\n",
    "        \"http://adapt2.sis.pitt.edu/pcex/index.html\",\n",
    "        \"http://pawscomp2.sis.pitt.edu/pcex/index.html\",\n",
    "        \"http://pawscomp2.sis.pitt.edu/pcex/pcex_v2/index.html\",\n",
    "    ]\n",
    "\n",
    "    for _, item in enumerate(catalog):\n",
    "        if len([1 for prefix in prefixes if item[\"url\"].startswith(prefix)]) == 0:\n",
    "            continue\n",
    "\n",
    "        iframe_url = item[\"url\"].split(\"index.html?\")[1].split(\"&\")\n",
    "        language = iframe_url[0].split(\"=\")[1]\n",
    "        problem_set = iframe_url[1].split(\"=\")[1]\n",
    "        challenge = iframe_url[2].split(\"=\")[1] if len(iframe_url) > 2 else None\n",
    "\n",
    "        content = requests.get(\n",
    "            f\"http://pawscomp2.sis.pitt.edu/pcex/pcex_v2/data/{language}_{problem_set}.json?v=201801041411\"\n",
    "        ).json()\n",
    "\n",
    "        content = (\n",
    "            content[\"activityGoals\"][0]\n",
    "            if challenge is None\n",
    "            else [\n",
    "                g\n",
    "                for g in content[\"activityGoals\"]\n",
    "                if g[\"fileName\"].startswith(challenge)\n",
    "            ][0]\n",
    "        )\n",
    "\n",
    "        metadata = dict()\n",
    "        if content[\"fullyWorkedOut\"] == False:\n",
    "            metadata[\"distractors\"] = []\n",
    "            for line in content[\"distractorList\"]:\n",
    "                line = line[\"line\"]\n",
    "                del line[\"id\"]\n",
    "                del line[\"indentLevel\"]\n",
    "                if \"number\" in line and line[\"number\"] > 0:\n",
    "                    line[\"line_number\"] = int(line[\"number\"])\n",
    "                del line[\"number\"]\n",
    "                metadata[\"distractors\"].append(line)\n",
    "\n",
    "        insert_content_attrs(\n",
    "            item[\"id\"],\n",
    "            content[\"goalDescription\"],\n",
    "            \"\\n\".join(\n",
    "                [\n",
    "                    l[\"content\"]\n",
    "                    for l in sorted(\n",
    "                        content[\"lineList\"],\n",
    "                        key=lambda l: int(l[\"number\"]),\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            item[\"url\"],\n",
    "            json.dumps(metadata) if len(metadata.keys()) > 0 else \"\",\n",
    "        )\n",
    "\n",
    "        print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "    agg_db.commit()\n",
    "\n",
    "\n",
    "process_pcex_v12_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b321759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS jsparsons-python CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def process_jsparsons_python_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://adapt2.sis.pitt.edu/acos/pitt/jsparsons/jsparsons-python/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         iframe_url = f\"{item['url']}&grp=demo&usr=demo&sid=-1&cid=-1\"\n",
    "#         content = requests.get(iframe_url).text\n",
    "\n",
    "#         code = (\n",
    "#             content[\n",
    "#                 content.find(\"parson.init('\") : content.find(\"parson.shuffleLines();\")\n",
    "#             ]\n",
    "#             .strip()[13:-3]\n",
    "#             .replace(\"\\\\n\", \"\\n\")\n",
    "#         )\n",
    "\n",
    "#         description_start = content.find('<div id=\"instructions\">')\n",
    "#         description = (\n",
    "#             content[\n",
    "#                 content.find('<div id=\"instructions\">') : content.find(\n",
    "#                     \"</div>\", description_start\n",
    "#                 )\n",
    "#                 + 6\n",
    "#             ]\n",
    "#             .replace('<div id=\"instructions\">', \"\")\n",
    "#             .strip()[5:-6]\n",
    "#             .strip()\n",
    "#         )\n",
    "\n",
    "#         insert_content_attrs(item[\"id\"], description, code, iframe_url, dict())\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_jsparsons_python_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS jsvee CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# jsvees = json.loads(open(\"./jsvee.json\").read())\n",
    "# jsvees = {k: \"\\n\".join(v[\"lines\"]) for k, v in jsvees.items()}\n",
    "\n",
    "\n",
    "# def process_jsvee_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix_pittpy = \"http://adapt2.sis.pitt.edu/acos/pitt/jsvee/jsvee-python/\"\n",
    "#     prefix_acospy = \"https://acos.cs.vt.edu/pitt/jsvee/jsvee-python/\"\n",
    "#     prefix_acosjava = \"https://acos.cs.vt.edu/pitt/jsvee/jsvee-java/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (\n",
    "#             item[\"url\"].startswith(prefix_pittpy)\n",
    "#             or item[\"url\"].startswith(prefix_acospy)\n",
    "#             or item[\"url\"].startswith(prefix_acosjava)\n",
    "#         ):\n",
    "#             continue\n",
    "\n",
    "#         example_id = item[\"url\"].split(\"?example-id=\")[1]\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             jsvees[example_id],\n",
    "#             f\"{item['url']}&grp=demo&usr=demo&sid=-1&cid=-1\",\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_jsvee_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS QuizPet CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "\n",
    "# def process_quizpet_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://adapt2.sis.pitt.edu/quizpet/displayQuiz.jsp\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = req.text\n",
    "#         code = content[\n",
    "#             content.find(\"<pre>\") + 5 : content.find(\"<form method=post>\")\n",
    "#         ].strip()\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             code,\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_quizpet_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS QuizJet CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "\n",
    "# def process_quizjet_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://pawscomp2.sis.pitt.edu/quizjet/displayQuiz.jsp\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = req.text\n",
    "#         code = content[\n",
    "#             content.find(\"<pre>\") + 5 : content.find(\"<form method=post>\")\n",
    "#         ].strip()\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             code,\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_quizjet_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS WebEx CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# def process_quizpet_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://adapt2.sis.pitt.edu/web_ex_NV0FGdaHzy/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             \"\\n\".join(\n",
    "#                 [\n",
    "#                     \"\\n\".join(\n",
    "#                         [ln for ln in tr.get_text().split(\"\\n\") if len(ln.strip()) > 0]\n",
    "#                     )\n",
    "#                     for tr in content.find_all(\"tr\")\n",
    "#                 ]\n",
    "#             ),\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_quizpet_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612087f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------- PROCESS AnnEx CONTENT -------------\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def process_annex_items():\n",
    "    print(\"connection to aggregate database established\")\n",
    "    prefix = \"http://adapt2.sis.pitt.edu/pitt/annotated/annotated-java/Dissection2\"\n",
    "\n",
    "    for _, item in enumerate(catalog):\n",
    "        if not (item[\"url\"].startswith(prefix)):\n",
    "            continue\n",
    "        \n",
    "        # \"http://adapt2.sis.pitt.edu/pitt/annotated/annotated-java/Dissection2?act=post_request_example\",\n",
    "        # \n",
    "        \n",
    "        url = \"http://adapt2.sis.pitt.edu/acos/html/annotated/annotated-java/\" + item[\"url\"].split('?act=')[-1]\n",
    "\n",
    "        req = requests.get(url)\n",
    "        if req.status_code != 200:\n",
    "            print(f\"Failed to retrieve {url}\")\n",
    "            continue\n",
    "\n",
    "        content = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "        insert_content_attrs(\n",
    "            item[\"id\"],\n",
    "            \"\",\n",
    "            \"\\n\".join(\n",
    "                [\n",
    "                    \"\\n\".join(\n",
    "                        [ln for ln in tr.get_text().split(\"\\n\") if len(ln.strip()) > 0]\n",
    "                    )\n",
    "                    for tr in content.find_all(\"tr\")\n",
    "                ]\n",
    "            ),\n",
    "            item[\"url\"],\n",
    "            dict(),\n",
    "        )\n",
    "\n",
    "        print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "    agg_db.commit()\n",
    "\n",
    "\n",
    "process_annex_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS Python-PCRS CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# def process_pcrs_python_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix_python = \"https://pcrs.utm.utoronto.ca/mgrids/problems/python/\"\n",
    "#     prefix_java = \"https://pcrs.utm.utoronto.ca/mgrids/problems/java/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (\n",
    "#             item[\"url\"].startswith(prefix_python) or item[\"url\"].startswith(prefix_java)\n",
    "#         ):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         description = content.find(\"h5\", {\"class\": \"problem-description\"}).get_text()\n",
    "#         code = content.find(\"div\", {\"id\": \"div_id_submission\"}).get_text().strip()\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             description,\n",
    "#             code,\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_pcrs_python_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64f401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # possible fixes to make content launch correctly in preview mode\n",
    "\n",
    "# -- # fix webex preview urls to include sid=demo\n",
    "# update ent_content_attrs set preview_url = REPLACE(preview_url, '&svc=progvis', '&svc=progvis&sid=demo')\n",
    "# where preview_url like 'http://adapt2.sis.pitt.edu/web_ex_NV0FGdaHzy/%&svc=progvis%'\n",
    "\n",
    "# -- # append \"&usr=demo\" to dbqa\n",
    "# -- http://adapt2.sis.pitt.edu/lti/launch?tool=dbqa&sub=select-from-3&usr=demo\n",
    "\n",
    "# -- # append \"&sid=demo&usr=demo&grp=demo\" to sqlknot\n",
    "# -- http://adapt2.sis.pitt.edu/sqlknot/index.html?cid=10&tid=4&svc=progvis&sid=demo&usr=demo&grp=demo\n",
    "\n",
    "# --  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
