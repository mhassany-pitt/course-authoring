{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38e3e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "catalog = json.loads(open(\"./catalog.json\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import configparser\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read(\"mysql.ini\")\n",
    "\n",
    "agg_db = mysql.connector.connect(\n",
    "    host=config[\"mysql\"][\"host\"],\n",
    "    user=config[\"mysql\"][\"username\"],\n",
    "    password=config[\"mysql\"][\"password\"],\n",
    "    ssl_disabled=True,  # Disable SSL\n",
    ")\n",
    "agg_cursor = agg_db.cursor()\n",
    "\n",
    "\n",
    "def insert_content_attrs(id, description, code, url, metadata):\n",
    "    agg_cursor.execute(\n",
    "        \"\"\"INSERT INTO aggregate.ent_content_attrs (content_id, description, code, preview_url, metadata) VALUES (%s, %s, %s, %s, %s)\"\"\",\n",
    "        (\n",
    "            id,\n",
    "            description,\n",
    "            code,\n",
    "            url,\n",
    "            json.dumps(metadata) if len(metadata.keys()) > 0 else \"\",\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6780a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS WEAT CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def process_weat_pcex_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "\n",
    "#     prefix = \"http://pawscomp2.sis.pitt.edu/pcex-authoring/preview/index.html?load=\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not item[\"url\"].startswith(prefix):\n",
    "#             continue\n",
    "#         iframe_url = item[\"url\"][len(prefix) :].split(\"?\")\n",
    "#         index = int(\n",
    "#             [p for p in iframe_url[1].split(\"&\") if p.startswith(\"index=\")][0].split(\n",
    "#                 \"=\"\n",
    "#             )[1]\n",
    "#         )\n",
    "#         content = requests.get(iframe_url[0]).json()[0]\n",
    "#         content = content[\"activityGoals\"][index]\n",
    "\n",
    "#         metadata = dict()\n",
    "\n",
    "#         if content[\"fullyWorkedOut\"] == False:\n",
    "#             metadata[\"distractors\"] = []\n",
    "#             for line in content[\"distractorList\"]:\n",
    "#                 line = line[\"line\"]\n",
    "#                 del line[\"id\"]\n",
    "#                 del line[\"indentLevel\"]\n",
    "#                 if \"number\" in line and line[\"number\"] > 0:\n",
    "#                     line[\"line_number\"] = int(line[\"number\"])\n",
    "#                 del line[\"number\"]\n",
    "#                 metadata[\"distractors\"].append(line)\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             content[\"goalDescription\"],\n",
    "#             \"\\n\".join(\n",
    "#                 [\n",
    "#                     l[\"content\"]\n",
    "#                     for l in sorted(\n",
    "#                         content[\"lineList\"],\n",
    "#                         key=lambda l: int(l[\"number\"]),\n",
    "#                     )\n",
    "#                 ]\n",
    "#             ),\n",
    "#             item[\"url\"],\n",
    "#             json.dumps(metadata) if len(metadata.keys()) > 0 else \"\",\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_weat_pcex_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231e3683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS PCEX-v1n2 CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def process_pcex_v12_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "\n",
    "#     prefix_v1 = \"http://pawscomp2.sis.pitt.edu/pcex/index.html\"\n",
    "#     prefix_v2 = \"http://pawscomp2.sis.pitt.edu/pcex/pcex_v2/index.html\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix_v1) or item[\"url\"].startswith(prefix_v2)):\n",
    "#             continue\n",
    "\n",
    "#         iframe_url = item[\"url\"].split(\"index.html?\")[1].split(\"&\")\n",
    "#         language = iframe_url[0].split(\"=\")[1]\n",
    "#         problem_set = iframe_url[1].split(\"=\")[1]\n",
    "#         challenge = iframe_url[2].split(\"=\")[1] if len(iframe_url) > 2 else None\n",
    "\n",
    "#         content = requests.get(\n",
    "#             f\"http://pawscomp2.sis.pitt.edu/pcex/pcex_v2/data/{language}_{problem_set}.json?v=201801041411\"\n",
    "#         ).json()\n",
    "\n",
    "#         content = (\n",
    "#             content[\"activityGoals\"][0]\n",
    "#             if challenge is None\n",
    "#             else [\n",
    "#                 g\n",
    "#                 for g in content[\"activityGoals\"]\n",
    "#                 if g[\"fileName\"].startswith(challenge)\n",
    "#             ][0]\n",
    "#         )\n",
    "\n",
    "#         metadata = dict()\n",
    "#         if content[\"fullyWorkedOut\"] == False:\n",
    "#             metadata[\"distractors\"] = []\n",
    "#             for line in content[\"distractorList\"]:\n",
    "#                 line = line[\"line\"]\n",
    "#                 del line[\"id\"]\n",
    "#                 del line[\"indentLevel\"]\n",
    "#                 if \"number\" in line and line[\"number\"] > 0:\n",
    "#                     line[\"line_number\"] = int(line[\"number\"])\n",
    "#                 del line[\"number\"]\n",
    "#                 metadata[\"distractors\"].append(line)\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             content[\"goalDescription\"],\n",
    "#             \"\\n\".join(\n",
    "#                 [\n",
    "#                     l[\"content\"]\n",
    "#                     for l in sorted(\n",
    "#                         content[\"lineList\"],\n",
    "#                         key=lambda l: int(l[\"number\"]),\n",
    "#                     )\n",
    "#                 ]\n",
    "#             ),\n",
    "#             item[\"url\"],\n",
    "#             json.dumps(metadata) if len(metadata.keys()) > 0 else \"\",\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_pcex_v12_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b321759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS jsparsons-python CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "\n",
    "\n",
    "# def process_jsparsons_python_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://adapt2.sis.pitt.edu/acos/pitt/jsparsons/jsparsons-python/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         iframe_url = f\"{item['url']}&grp=demo&usr=demo&sid=-1&cid=-1\"\n",
    "#         content = requests.get(iframe_url).text\n",
    "\n",
    "#         code = (\n",
    "#             content[\n",
    "#                 content.find(\"parson.init('\") : content.find(\"parson.shuffleLines();\")\n",
    "#             ]\n",
    "#             .strip()[13:-3]\n",
    "#             .replace(\"\\\\n\", \"\\n\")\n",
    "#         )\n",
    "\n",
    "#         description_start = content.find('<div id=\"instructions\">')\n",
    "#         description = (\n",
    "#             content[\n",
    "#                 content.find('<div id=\"instructions\">') : content.find(\n",
    "#                     \"</div>\", description_start\n",
    "#                 )\n",
    "#                 + 6\n",
    "#             ]\n",
    "#             .replace('<div id=\"instructions\">', \"\")\n",
    "#             .strip()[5:-6]\n",
    "#             .strip()\n",
    "#         )\n",
    "\n",
    "#         insert_content_attrs(item[\"id\"], description, code, iframe_url, dict())\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_jsparsons_python_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4f18bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS jsvee CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "# jsvees = json.loads(open(\"./jsvee.json\").read())\n",
    "# jsvees = {k: \"\\n\".join(v[\"lines\"]) for k, v in jsvees.items()}\n",
    "\n",
    "\n",
    "# def process_jsvee_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix_pittpy = \"http://adapt2.sis.pitt.edu/acos/pitt/jsvee/jsvee-python/\"\n",
    "#     prefix_acospy = \"https://acos.cs.vt.edu/pitt/jsvee/jsvee-python/\"\n",
    "#     prefix_acosjava = \"https://acos.cs.vt.edu/pitt/jsvee/jsvee-java/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (\n",
    "#             item[\"url\"].startswith(prefix_pittpy)\n",
    "#             or item[\"url\"].startswith(prefix_acospy)\n",
    "#             or item[\"url\"].startswith(prefix_acosjava)\n",
    "#         ):\n",
    "#             continue\n",
    "\n",
    "#         example_id = item[\"url\"].split(\"?example-id=\")[1]\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             jsvees[example_id],\n",
    "#             f\"{item['url']}&grp=demo&usr=demo&sid=-1&cid=-1\",\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_jsvee_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee1fa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS QuizPet CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "\n",
    "# def process_quizpet_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://adapt2.sis.pitt.edu/quizpet/displayQuiz.jsp\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = req.text\n",
    "#         code = content[\n",
    "#             content.find(\"<pre>\") + 5 : content.find(\"<form method=post>\")\n",
    "#         ].strip()\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             code,\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_quizpet_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2f171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS QuizJet CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "\n",
    "\n",
    "# def process_quizjet_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://pawscomp2.sis.pitt.edu/quizjet/displayQuiz.jsp\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = req.text\n",
    "#         code = content[\n",
    "#             content.find(\"<pre>\") + 5 : content.find(\"<form method=post>\")\n",
    "#         ].strip()\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             code,\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_quizjet_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS WebEx CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# def process_quizpet_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix = \"http://adapt2.sis.pitt.edu/web_ex_NV0FGdaHzy/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (item[\"url\"].startswith(prefix)):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = BeautifulSoup(req.text, \"html.parser\")\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             \"\",\n",
    "#             \"\\n\".join(\n",
    "#                 [\n",
    "#                     \"\\n\".join(\n",
    "#                         [ln for ln in tr.get_text().split(\"\\n\") if len(ln.strip()) > 0]\n",
    "#                     )\n",
    "#                     for tr in content.find_all(\"tr\")\n",
    "#                 ]\n",
    "#             ),\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_quizpet_items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcf4227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ------------- PROCESS Python-PCRS CONTENT -------------\n",
    "\n",
    "# import re\n",
    "# import requests\n",
    "# import json\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "# def process_pcrs_python_items():\n",
    "#     print(\"connection to aggregate database established\")\n",
    "#     prefix_python = \"https://pcrs.utm.utoronto.ca/mgrids/problems/python/\"\n",
    "#     prefix_java = \"https://pcrs.utm.utoronto.ca/mgrids/problems/java/\"\n",
    "\n",
    "#     for _, item in enumerate(catalog):\n",
    "#         if not (\n",
    "#             item[\"url\"].startswith(prefix_python) or item[\"url\"].startswith(prefix_java)\n",
    "#         ):\n",
    "#             continue\n",
    "\n",
    "#         req = requests.get(item[\"url\"])\n",
    "#         if req.status_code != 200:\n",
    "#             print(f\"Failed to retrieve {item['url']}\")\n",
    "#             continue\n",
    "\n",
    "#         content = BeautifulSoup(req.text, \"html.parser\")\n",
    "#         description = content.find(\"h5\", {\"class\": \"problem-description\"}).get_text()\n",
    "#         code = content.find(\"div\", {\"id\": \"div_id_submission\"}).get_text().strip()\n",
    "\n",
    "#         insert_content_attrs(\n",
    "#             item[\"id\"],\n",
    "#             description,\n",
    "#             code,\n",
    "#             item[\"url\"],\n",
    "#             dict(),\n",
    "#         )\n",
    "\n",
    "#         print(f\"processed content_id: {item['id']}\")\n",
    "\n",
    "#     agg_db.commit()\n",
    "\n",
    "\n",
    "# process_pcrs_python_items()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
